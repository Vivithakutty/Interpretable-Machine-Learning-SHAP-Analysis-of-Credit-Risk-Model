# -*- coding: utf-8 -*-
"""PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kjY6y2tmI1gStK4Ms2olmByIqjDjFsx7

## **Interpretable Machine Learning: SHAP Analysis of Credit Risk Model**

## **IMPORT LIBRARIES**
"""

import pandas as pd
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import roc_auc_score, f1_score, classification_report
from lightgbm import LGBMClassifier
import shap
import matplotlib.pyplot as plt
import seaborn as sns

"""## **Display 5 row of dataset**"""

from sklearn.datasets import fetch_openml
import pandas as pd

data = fetch_openml("credit-g", version=1, as_frame=True)
df = data.frame.copy()

df.head()

"""## **Class Risk - Good/Bad**"""

df['class'] = df['class'].map({'good': 0, 'bad': 1})
df.head()

"""## **preprocess**- split"""

y = df["class"]
X = df.drop("class", axis=1)

X = pd.get_dummies(X, drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""## **Train and Hyperparameter grid**"""

params = {
    "num_leaves": [31, 50],
    "learning_rate": [0.01, 0.05, 0.1],
    "n_estimators": [100, 300]
}

"""## **Gradient Boosting Machine (LightGBM)**"""

model = LGBMClassifier()

grid = GridSearchCV(model, params, cv=5, scoring="f1", n_jobs=-1)
grid.fit(X_train, y_train)

best_model = grid.best_estimator_

"""## **Model Evaluation**"""

y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:,1]

auc = roc_auc_score(y_test, y_prob)
f1 = f1_score(y_test, y_pred)

print("AUC:", auc)
print("F1 Score:", f1)
print(classification_report(y_test, y_pred))

"""## **SHAP Analysis**"""

explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)

"""## **Extract Features and Plot**"""

top_features = X_test.columns[np.argsort(np.abs(shap_values).mean(0))[-5:]]

for f in top_features:
    shap.dependence_plot(f, shap_values, X_test)

"""## **SHAP Explanation**"""

expected_value_for_class_1 = explainer.expected_value

instances = X_test.sample(5, random_state=42)

for original_idx, instance_row in instances.iterrows():
    pos_idx = X_test.index.get_loc(original_idx)

    shap.force_plot(
        expected_value_for_class_1,
        shap_values[pos_idx]
        instance_row,
        matplotlib=True
    )

"""## **SHAP Age Group**"""

df['age_group'] = pd.cut(df['age'], bins=[0, 25, 60], labels=["young", "adult"])

#Compare Average SHAP Values by Age Group

group_shap = pd.DataFrame(shap_values, columns=X_test.columns)
group_shap['age_group'] = df.loc[X_test.index, 'age_group']

group_means = group_shap.groupby("age_group").mean().T
group_means.head()

"""## **Average Difference bettween Age Group**"""

group_means.plot(kind='bar', figsize=(12,6))
plt.title("Average SHAP Values by Age Group")
plt.show()